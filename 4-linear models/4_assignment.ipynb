{"cells":[{"metadata":{"_uuid":"3f6c2bfe6b2e26c92357e896a1511195d836956e"},"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\">\n    \n## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \nAuthor: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."},{"metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"},"cell_type":"markdown","source":"## <center> Assignment 4. Sarcasm detection with logistic regression\n    \nWe'll be using the dataset from the [paper](https://arxiv.org/abs/1704.05579) \"A Large Self-Annotated Corpus for Sarcasm\" with >1mln comments from Reddit, labeled as either sarcastic or not. A processed version can be found on Kaggle in a form of a [Kaggle Dataset](https://www.kaggle.com/danofer/sarcasm).\n\nSarcasm detection is easy. \n<img src=\"https://habrastorage.org/webt/1f/0d/ta/1f0dtavsd14ncf17gbsy1cvoga4.jpeg\" />"},{"metadata":{"trusted":true,"_uuid":"23a833b42b3c214b5191dfdc2482f2f901118247"},"cell_type":"code","source":"!ls ../input/sarcasm/","execution_count":1,"outputs":[{"output_type":"stream","text":"test-balanced.csv    train-balanced-sarc.csv.gz\r\ntest-unbalanced.csv  train-balanced-sarcasm.csv\r\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4"},"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nfrom matplotlib import pyplot as plt","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856"},"cell_type":"code","source":"train_df = pd.read_csv('../input/sarcasm/train-balanced-sarcasm.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27"},"cell_type":"code","source":"train_df.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   label                        ...                                                             parent_comment\n0      0                        ...                          Yeah, I get that argument. At this point, I'd ...\n1      0                        ...                          The blazers and Mavericks (The wests 5 and 6 s...\n2      0                        ...                                                    They're favored to win.\n3      0                        ...                                                 deadass don't kill my buzz\n4      0                        ...                          Yep can confirm I saw the tool they use for th...\n\n[5 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>comment</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>score</th>\n      <th>ups</th>\n      <th>downs</th>\n      <th>date</th>\n      <th>created_utc</th>\n      <th>parent_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NC and NH.</td>\n      <td>Trumpbart</td>\n      <td>politics</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-16 23:55:23</td>\n      <td>Yeah, I get that argument. At this point, I'd ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>You do know west teams play against west teams...</td>\n      <td>Shbshb906</td>\n      <td>nba</td>\n      <td>-4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-11</td>\n      <td>2016-11-01 00:24:10</td>\n      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>They were underdogs earlier today, but since G...</td>\n      <td>Creepeth</td>\n      <td>nfl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2016-09</td>\n      <td>2016-09-22 21:45:37</td>\n      <td>They're favored to win.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>This meme isn't funny none of the \"new york ni...</td>\n      <td>icebrotha</td>\n      <td>BlackPeopleTwitter</td>\n      <td>-8</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-10</td>\n      <td>2016-10-18 21:03:47</td>\n      <td>deadass don't kill my buzz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>I could use one of those tools.</td>\n      <td>cush2push</td>\n      <td>MaddenUltimateTeam</td>\n      <td>6</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2016-12</td>\n      <td>2016-12-30 17:00:13</td>\n      <td>Yep can confirm I saw the tool they use for th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"0a7ed9557943806c6813ad59c3d5ebdb403ffd78"},"cell_type":"code","source":"train_df.info()","execution_count":5,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1010826 entries, 0 to 1010825\nData columns (total 10 columns):\nlabel             1010826 non-null int64\ncomment           1010773 non-null object\nauthor            1010826 non-null object\nsubreddit         1010826 non-null object\nscore             1010826 non-null int64\nups               1010826 non-null int64\ndowns             1010826 non-null int64\ndate              1010826 non-null object\ncreated_utc       1010826 non-null object\nparent_comment    1010826 non-null object\ndtypes: int64(4), object(6)\nmemory usage: 77.1+ MB\n","name":"stdout"}]},{"metadata":{"_uuid":"6472f52fb5ecb8bb2a6e3b292678a2042fcfe34c"},"cell_type":"markdown","source":"Some comments are missing, so we drop the corresponding rows."},{"metadata":{"trusted":true,"_uuid":"97b2d85627fcde52a506dbdd55d4d6e4c87d3f08"},"cell_type":"code","source":"train_df.dropna(subset=['comment'], inplace=True)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"},"cell_type":"markdown","source":"We notice that the dataset is indeed balanced"},{"metadata":{"trusted":true,"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11"},"cell_type":"code","source":"train_df['label'].value_counts()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"0    505405\n1    505368\nName: label, dtype: int64"},"metadata":{}}]},{"metadata":{"_uuid":"5b836574e5093c5eb2e9063fefe1c8d198dcba79"},"cell_type":"markdown","source":"We split data into training and validation parts."},{"metadata":{"trusted":true,"_uuid":"c200add4e1dcbaa75164bbcc73b9c12ecb863c96"},"cell_type":"code","source":"train_texts, valid_texts, y_train, y_valid = train_test_split(train_df['comment'], train_df['label'], random_state=17)","execution_count":8,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7f0f47b98e49a185cd5cffe19fcbe28409bf00c0"},"cell_type":"markdown","source":"## Tasks:\n1. Analyze the dataset, make some plots. This [Kernel](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc) might serve as an example\n2. Build a Tf-Idf + logistic regression pipeline to predict sarcasm (`label`) based on the text of a comment on Reddit (`comment`).\n3. Plot the words/bigrams which a most predictive of sarcasm (you can use [eli5](https://github.com/TeamHG-Memex/eli5) for that)\n4. (optionally) add subreddits as new features to improve model performance. Apply here the Bag of Words approach, i.e. treat each subreddit as a new feature.\n\n## Links:\n  - Machine learning library [Scikit-learn](https://scikit-learn.org/stable/index.html) (a.k.a. sklearn)\n  - Kernels on [logistic regression](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-2-classification) and its applications to [text classification](https://www.kaggle.com/kashnitsky/topic-4-linear-models-part-4-more-of-logit), also a [Kernel](https://www.kaggle.com/kashnitsky/topic-6-feature-engineering-and-feature-selection) on feature engineering and feature selection\n  - [Kaggle Kernel](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle) \"Approaching (Almost) Any NLP Problem on Kaggle\"\n  - [ELI5](https://github.com/TeamHG-Memex/eli5) to explain model predictions"},{"metadata":{},"cell_type":"markdown","source":"Distribution of lengths for sarcastic and normal comments is almost the same:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df['label'] == 1]['comment'].str.len().apply(np.log1p).hist(label='sarcastic', alpha=.5)\ntrain_df[train_df['label'] == 0]['comment'].str.len().apply(np.log1p).hist(label='normal', alpha=.5)\nplt.legend();","execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Nothing interesting for same authors"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = train_df.groupby('author')['label'].agg([np.size, np.mean])\nsub_df[sub_df['size'] > 100].sort_values(by='mean').head(10)","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"                size      mean\nauthor                        \nradpandaparty    104  0.490385\nindoninja        106  0.490566\nward0630         101  0.495050\nfitzroy95        111  0.495495\nYah-luna-tic     113  0.495575\niam4real         123  0.495935\nMad_Hatter_Bot   131  0.496183\nukulelej         137  0.496350\nFNAFfan69        137  0.496350\nJumpingJazzJam   199  0.497487","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>mean</th>\n    </tr>\n    <tr>\n      <th>author</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>radpandaparty</th>\n      <td>104</td>\n      <td>0.490385</td>\n    </tr>\n    <tr>\n      <th>indoninja</th>\n      <td>106</td>\n      <td>0.490566</td>\n    </tr>\n    <tr>\n      <th>ward0630</th>\n      <td>101</td>\n      <td>0.495050</td>\n    </tr>\n    <tr>\n      <th>fitzroy95</th>\n      <td>111</td>\n      <td>0.495495</td>\n    </tr>\n    <tr>\n      <th>Yah-luna-tic</th>\n      <td>113</td>\n      <td>0.495575</td>\n    </tr>\n    <tr>\n      <th>iam4real</th>\n      <td>123</td>\n      <td>0.495935</td>\n    </tr>\n    <tr>\n      <th>Mad_Hatter_Bot</th>\n      <td>131</td>\n      <td>0.496183</td>\n    </tr>\n    <tr>\n      <th>ukulelej</th>\n      <td>137</td>\n      <td>0.496350</td>\n    </tr>\n    <tr>\n      <th>FNAFfan69</th>\n      <td>137</td>\n      <td>0.496350</td>\n    </tr>\n    <tr>\n      <th>JumpingJazzJam</th>\n      <td>199</td>\n      <td>0.497487</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let's consider subreddits"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = train_df.groupby('subreddit')['label'].agg([np.size, np.mean])\nprint(sub_df[sub_df['size'] > 1000].sort_values(by='mean').head(10))\nprint(sub_df[sub_df['size'] > 1000].sort_values(by='mean', ascending=False).head(10))","execution_count":32,"outputs":[{"output_type":"stream","text":"                     size      mean\nsubreddit                          \nGames                1341  0.227442\n4chan                1074  0.245810\naww                  2493  0.315684\nscience              1126  0.377442\nBlackPeopleTwitter   1831  0.379574\nJokes                1378  0.381713\nfantasyfootball      2274  0.386104\nAskReddit           65674  0.401453\nanime                1690  0.403550\ngifs                 5267  0.411620\n                  size      mean\nsubreddit                       \ncreepyPMs         5466  0.784303\nMensRights        3355  0.680775\nShitRedditSays    1284  0.661994\nworldnews        26376  0.642516\nLibertarian       2562  0.640125\natheism           7377  0.639555\nConservative      1881  0.639553\nTwoXChromosomes   1560  0.632692\nfatlogic          2356  0.623090\nfacepalm          1268  0.617508\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Really nice for some sub_reddits!"},{"metadata":{},"cell_type":"markdown","source":"Training the model"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}